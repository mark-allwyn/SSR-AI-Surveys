================================================================================
GROUND TRUTH COMPARISON REPORT: HUMAN GROUND TRUTH VS LLM+SSR
================================================================================

Survey: Online Lottery Gaming Platform Evaluation
Questions Analyzed: 6

--------------------------------------------------------------------------------
OVERALL SUMMARY
--------------------------------------------------------------------------------

Average Mode Accuracy:
  Ground Truth (Human): 100.0%
  LLM+SSR:              92.7%
  Gap:                  7.3%

Average MAE:
  Ground Truth (Human): 0.000
  LLM+SSR:              0.575

--------------------------------------------------------------------------------
QUESTION: q1_would_subscribe
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 96.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.040
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.200

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.040  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.200  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.960
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0062

--------------------------------------------------------------------------------
QUESTION: q2_subscription_likelihood
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 72.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.280
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.529

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.881  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 1.060  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.403
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0706

--------------------------------------------------------------------------------
QUESTION: q3_platform_trust
--------------------------------------------------------------------------------

Question Type: likert_7
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 92.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.100
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.374

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 1.362  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 1.597  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.257
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.1108

--------------------------------------------------------------------------------
QUESTION: q4_price_preference
--------------------------------------------------------------------------------

Question Type: multiple_choice
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 100.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.000
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.000

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.641  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.752  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.404
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0884

--------------------------------------------------------------------------------
QUESTION: q5_recommend
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 98.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.020
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.141

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.020  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.141  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.980
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0012

--------------------------------------------------------------------------------
QUESTION: q6_feature_importance
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 98.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 98.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.020
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.141

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.507  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.563  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.501
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0663

================================================================================
END OF REPORT
================================================================================
