================================================================================
GROUND TRUTH COMPARISON REPORT: HUMAN GROUND TRUTH VS LLM+SSR
================================================================================

Survey: Online Lottery Gaming Platform Evaluation
Questions Analyzed: 6

--------------------------------------------------------------------------------
OVERALL SUMMARY
--------------------------------------------------------------------------------

Average Mode Accuracy:
  Ground Truth (Human): 100.0%
  LLM+SSR:              91.0%
  Gap:                  9.0%

Average MAE:
  Ground Truth (Human): 0.000
  LLM+SSR:              0.686

--------------------------------------------------------------------------------
QUESTION: q1_would_subscribe
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 88.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.120
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.346

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.120  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.346  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.880
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0291

--------------------------------------------------------------------------------
QUESTION: q2_subscription_likelihood
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 88.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.120
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.346

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.948  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 1.106  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.403
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0836

--------------------------------------------------------------------------------
QUESTION: q3_platform_trust
--------------------------------------------------------------------------------

Question Type: likert_7
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 84.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.200
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.529

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 1.651  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 1.860  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.253
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.2978

--------------------------------------------------------------------------------
QUESTION: q4_price_preference
--------------------------------------------------------------------------------

Question Type: multiple_choice
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 100.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.000
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.000

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.677  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.793  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.419
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.1204

--------------------------------------------------------------------------------
QUESTION: q5_recommend
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 86.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.140
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.374

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.140  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.374  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.860
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.0444

--------------------------------------------------------------------------------
QUESTION: q6_feature_importance
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:          Ground Truth: 100.0%  |  LLM+SSR: 100.0%
Top-2 Accuracy:         Ground Truth: 100.0%  |  LLM+SSR: 100.0%

MAE (Mode):             Ground Truth: 0.000  |  LLM+SSR: 0.000
RMSE (Mode):            Ground Truth: 0.000  |  LLM+SSR: 0.000

MAE (Expected Value):   Ground Truth: 0.000  |  LLM+SSR: 0.581  [More robust]
RMSE (Expected Value):  Ground Truth: 0.000  |  LLM+SSR: 0.622  [More robust]

Prob at Truth:          Ground Truth: 1.000  |  LLM+SSR: 0.533
KL Divergence:          Ground Truth: 0.0000  |  LLM+SSR: 0.1236

================================================================================
END OF REPORT
================================================================================
