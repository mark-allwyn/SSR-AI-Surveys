================================================================================
GROUND TRUTH COMPARISON REPORT: HUMAN VS LLM
================================================================================

Survey: Online Lottery Gaming Platform Evaluation
Questions Analyzed: 6

--------------------------------------------------------------------------------
OVERALL SUMMARY
--------------------------------------------------------------------------------

Average Mode Accuracy:
  Human: 93.7%
  LLM:   93.0%
  Winner: Human

Average MAE:
  Human: 0.063
  LLM:   0.073
  Winner: Human

--------------------------------------------------------------------------------
QUESTION: q1_would_subscribe
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 92.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.080
RMSE:               Human: 0.000  |  LLM: 0.283
Prob at Truth:      Human: 1.000  |  LLM: 0.920
KL Divergence:      Human: 0.0000  |  LLM: 0.0142

--------------------------------------------------------------------------------
QUESTION: q2_subscription_likelihood
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:      Human: 62.0%  |  LLM: 84.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.380  |  LLM: 0.160
RMSE:               Human: 0.616  |  LLM: 0.400
Prob at Truth:      Human: 0.428  |  LLM: 0.406
KL Divergence:      Human: 0.0163  |  LLM: 0.0216

--------------------------------------------------------------------------------
QUESTION: q3_platform_trust
--------------------------------------------------------------------------------

Question Type: likert_7
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 92.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.100
RMSE:               Human: 0.000  |  LLM: 0.374
Prob at Truth:      Human: 0.280  |  LLM: 0.249
KL Divergence:      Human: 0.0636  |  LLM: 0.1072

--------------------------------------------------------------------------------
QUESTION: q4_price_preference
--------------------------------------------------------------------------------

Question Type: multiple_choice
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 100.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.000
RMSE:               Human: 0.000  |  LLM: 0.000
Prob at Truth:      Human: 0.424  |  LLM: 0.400
KL Divergence:      Human: 0.0844  |  LLM: 0.1215

--------------------------------------------------------------------------------
QUESTION: q5_recommend
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 90.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.100
RMSE:               Human: 0.000  |  LLM: 0.316
Prob at Truth:      Human: 1.000  |  LLM: 0.900
KL Divergence:      Human: 0.0000  |  LLM: 0.0220

--------------------------------------------------------------------------------
QUESTION: q6_feature_importance
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 100.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.000
RMSE:               Human: 0.000  |  LLM: 0.000
Prob at Truth:      Human: 0.587  |  LLM: 0.512
KL Divergence:      Human: 0.0208  |  LLM: 0.0584

================================================================================
END OF REPORT
================================================================================
