================================================================================
GROUND TRUTH COMPARISON REPORT: HUMAN VS LLM
================================================================================

Survey: Online Lottery Gaming Platform Evaluation
Questions Analyzed: 6

--------------------------------------------------------------------------------
OVERALL SUMMARY
--------------------------------------------------------------------------------

Average Mode Accuracy:
  Human: 93.3%
  LLM:   90.0%
  Winner: Human

Average MAE:
  Human: 0.067
  LLM:   0.103
  Winner: Human

--------------------------------------------------------------------------------
QUESTION: q1_would_subscribe
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 92.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.080
RMSE:               Human: 0.000  |  LLM: 0.283
Prob at Truth:      Human: 1.000  |  LLM: 0.920
KL Divergence:      Human: 0.0000  |  LLM: 0.0146

--------------------------------------------------------------------------------
QUESTION: q2_subscription_likelihood
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:      Human: 60.0%  |  LLM: 74.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.400  |  LLM: 0.260
RMSE:               Human: 0.632  |  LLM: 0.510
Prob at Truth:      Human: 0.399  |  LLM: 0.382
KL Divergence:      Human: 0.0111  |  LLM: 0.0137

--------------------------------------------------------------------------------
QUESTION: q3_platform_trust
--------------------------------------------------------------------------------

Question Type: likert_7
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 90.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.120
RMSE:               Human: 0.000  |  LLM: 0.400
Prob at Truth:      Human: 0.281  |  LLM: 0.251
KL Divergence:      Human: 0.0309  |  LLM: 0.0695

--------------------------------------------------------------------------------
QUESTION: q4_price_preference
--------------------------------------------------------------------------------

Question Type: multiple_choice
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 100.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.000
RMSE:               Human: 0.000  |  LLM: 0.000
Prob at Truth:      Human: 0.445  |  LLM: 0.409
KL Divergence:      Human: 0.0757  |  LLM: 0.1115

--------------------------------------------------------------------------------
QUESTION: q5_recommend
--------------------------------------------------------------------------------

Question Type: yes_no
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 88.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 100.0%
MAE:                Human: 0.000  |  LLM: 0.120
RMSE:               Human: 0.000  |  LLM: 0.346
Prob at Truth:      Human: 1.000  |  LLM: 0.880
KL Divergence:      Human: 0.0000  |  LLM: 0.0297

--------------------------------------------------------------------------------
QUESTION: q6_feature_importance
--------------------------------------------------------------------------------

Question Type: likert_5
Sample Size: 50

Mode Accuracy:      Human: 100.0%  |  LLM: 96.0%
Top-2 Accuracy:     Human: 100.0%  |  LLM: 96.0%
MAE:                Human: 0.000  |  LLM: 0.040
RMSE:               Human: 0.000  |  LLM: 0.200
Prob at Truth:      Human: 0.573  |  LLM: 0.520
KL Divergence:      Human: 0.0277  |  LLM: 0.0464

================================================================================
END OF REPORT
================================================================================
